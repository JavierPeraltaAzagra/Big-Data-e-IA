{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0bdb4dbb",
   "metadata": {},
   "source": [
    "# Consultas PySpark y limpieza de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a9b094b",
   "metadata": {},
   "source": [
    "Importamos pyspark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5aadb995",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://3MASANZ-A21E14:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v4.0.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Earthquake</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x1a91b6de210>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importaciones\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession, functions as F, types as T\n",
    "\n",
    "spark = SparkSession.builder.appName(\"Earthquake\").getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd7b9e22",
   "metadata": {},
   "source": [
    "Realiza la limpieza de datos del siguiente CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a11d7cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (spark.read\n",
    "      .option(\"header\", True)\n",
    "      .option(\"inferSchema\", True)\n",
    "      .csv(\"earthquake_data_tsunami.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b69d1247",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+---+---+---+----+---+-----+--------+---------+----+-----+-------+\n",
      "|magnitude|cdi|mmi|sig|nst|dmin|gap|depth|latitude|longitude|Year|Month|tsunami|\n",
      "+---------+---+---+---+---+----+---+-----+--------+---------+----+-----+-------+\n",
      "|        0|  0|  0|  0|  0|   0|  0|    0|       0|        0|   0|    0|      0|\n",
      "+---------+---+---+---+---+----+---+-----+--------+---------+----+-----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nulos = df.select([F.count(F.when(F.col(c).isNull(), c)).alias(c) for c in df.columns])\n",
    "nulos.show()\n",
    "nulos = nulos.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "731a6c22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[magnitude: double, cdi: int, mmi: int, sig: int, nst: int, dmin: double, gap: double, depth: double, latitude: double, longitude: double, Year: int, Month: int, tsunami: int]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dropDuplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb382cca",
   "metadata": {},
   "source": [
    "Contar cuantos eventos suceden por mes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b989b582",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|Month|count|\n",
      "+-----+-----+\n",
      "|    1|   70|\n",
      "|    2|   63|\n",
      "|    3|   63|\n",
      "|    4|   77|\n",
      "|    5|   58|\n",
      "|    6|   42|\n",
      "|    7|   56|\n",
      "|    8|   68|\n",
      "|    9|   80|\n",
      "|   10|   69|\n",
      "|   11|   80|\n",
      "|   12|   56|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "eventos_mes = df.groupBy(\"Month\").count().orderBy(\"Month\")\n",
    "eventos_mes.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7eadcb4",
   "metadata": {},
   "source": [
    "Máximo de magnitud de terremotos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e9b466c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|max_magnitude|\n",
      "+-------------+\n",
      "|          9.1|\n",
      "+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.createOrReplaceTempView(\"Earthquake\")\n",
    "maximo_magnitud = spark.sql(\"SELECT MAX(magnitude) as max_magnitude FROM Earthquake\")\n",
    "maximo_magnitud.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548c9485",
   "metadata": {},
   "source": [
    "Top 10 años que mas aparecen en el CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2327fb94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+\n",
      "|Year|Count|\n",
      "+----+-----+\n",
      "|2015|   53|\n",
      "|2013|   53|\n",
      "|2014|   48|\n",
      "|2018|   43|\n",
      "|2016|   43|\n",
      "|2021|   42|\n",
      "|2010|   41|\n",
      "|2022|   40|\n",
      "|2007|   37|\n",
      "|2017|   36|\n",
      "+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "años_top10 = spark.sql(\"SELECT Year, COUNT(Year) as Count FROM Earthquake GROUP BY Year ORDER BY Count DESC LIMIT 10\")\n",
    "años_top10.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d53a3d8",
   "metadata": {},
   "source": [
    "Magnitud Media por año."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53d3a4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------------+\n",
      "|Year|           Average|\n",
      "+----+------------------+\n",
      "|2022|            6.8125|\n",
      "|2021|  7.05238095238095|\n",
      "|2020|  6.91111111111111|\n",
      "|2019|6.8606060606060595|\n",
      "|2018| 6.953488372093025|\n",
      "|2017| 6.811111111111113|\n",
      "|2016| 6.944186046511627|\n",
      "|2015| 6.898113207547171|\n",
      "|2014| 6.843749999999999|\n",
      "|2013| 6.890566037735849|\n",
      "|2012| 7.070967741935481|\n",
      "|2011| 6.988235294117645|\n",
      "|2010| 7.004878048780489|\n",
      "|2009|  7.16153846153846|\n",
      "|2008| 6.900000000000001|\n",
      "|2007| 7.054054054054053|\n",
      "|2006|  6.94230769230769|\n",
      "|2005| 6.942857142857142|\n",
      "|2004| 6.959374999999999|\n",
      "|2003| 6.889032258064517|\n",
      "+----+------------------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "magnitud_media = spark.sql(\"SELECT Year, AVG(Magnitude) as Average FROM Earthquake GROUP BY Year ORDER BY Year DESC\")\n",
    "magnitud_media.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94bba789",
   "metadata": {},
   "source": [
    "Máximo de magnitud por mes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9d5822ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------------+\n",
      "|Month|MaxMagnitude|\n",
      "+-----+------------+\n",
      "|    1|         8.1|\n",
      "|    2|         8.8|\n",
      "|    3|         9.1|\n",
      "|    4|         8.6|\n",
      "|    5|         8.3|\n",
      "|    6|         8.4|\n",
      "|    7|         8.2|\n",
      "|    8|         8.2|\n",
      "|    9|         8.4|\n",
      "|   10|         7.8|\n",
      "|   11|         8.3|\n",
      "|   12|         9.1|\n",
      "+-----+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "max_magnitud_mes = spark.sql(\"SELECT Month, MAX(Magnitude) as MaxMagnitude FROM Earthquake GROUP BY Month ORDER BY Month\")\n",
    "max_magnitud_mes.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
